{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load some stuff, and create a so called Model Schema, that will allow the model to return structured output that can then easily be converted into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import pandas as pd\n",
    "from contextlib import redirect_stdout\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "oai_keyfile = \"oai_key.py\"\n",
    "\n",
    "openai_key = {}\n",
    "with open(oai_keyfile) as f:\n",
    "    exec(f.read(), openai_key)\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openai_key['openai_key'])\n",
    "\n",
    "class TestStatistic(BaseModel):\n",
    "    statistic_type: str  # e.g., 't', 'F', 'z', etc.\n",
    "    value: float\n",
    "    degrees_of_freedom: Optional[str] # e.g., 'df=20'\n",
    "    p_value_exact: Optional[bool] # should be true if p-value is reported with = sign or false if < or > \n",
    "    p_value: Optional[float]\n",
    "    confidence_interval: Optional[str] # e.g., '95% CI [1.2, 3.4]'\n",
    "    effect_measure: Optional[str] # e.g., 'r', 'OR', 'RR', d, \n",
    "    effect_size: Optional[str] # e.g., 'd=0.5'\n",
    "    hypothesis_confirmed: Optional[bool] # should be true if p-value is less than alpha level and in line with hypothesized direction\n",
    "    \n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "class Hypothesis(BaseModel):\n",
    "    hypothesis_text: str\n",
    "    test_statistics: List[TestStatistic]\n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "class Study(BaseModel):\n",
    "    study_title: str\n",
    "    hypotheses: List[Hypothesis]\n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "    paper_title: str\n",
    "    file_name: str\n",
    "    studies: List[Study]\n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "# print(ResearchPaper.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an assistant, which is basically a persistant GPT instance (like a digital RA) that we pass our papers to and ask it to complete the task. Unlike an actual RA, it will always forget what it did in between papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Research Paper Extractor\",\n",
    "    instructions=\"You are a skilled researcher tasked with accurately and completely extracting hypotheses and test results from a research paper and providing the output in structured JSON format.\",\n",
    "    model=\"gpt-4o\",  # Ensure this model supports structured outputs\n",
    "    temperature=0.1,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"ResearchPaper\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": ResearchPaper.model_json_schema()\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# check if token usage file exists\n",
    "if not os.path.exists(\"token_usage.txt\"):\n",
    "  f = open(\"token_usage.txt\", \"w\")\n",
    "  f.write(\"0\\n\")\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we point to some directory (yes I know this is not how I should be doing folder management, I'll change that at some point), and take some pdfs in there for testing this approach. Usually we would want to use all that we are interested in, now we just sample a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PDF files: ['10117709567976241235932.pdf', '10117709567976231222836.pdf', '10117709567976241246561.pdf', '10117709567976241242105.pdf', '10117709567976241239932.pdf', '10117709567976241254312.pdf', '10117709567976231215298.pdf', '10117709567976231221789.pdf', '10117709567976241243370.pdf', '10117709567976231221990.pdf']\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/home/julian/projects/auto_rep_dgps/downloads/Psychological_Science/\"\n",
    "\n",
    "# Get a list of all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(filepath) if f.endswith('.pdf')]\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Select 10 random PDF files\n",
    "selected_pdfs = random.sample(pdf_files, 10)\n",
    "\n",
    "print(\"Selected PDF files:\", selected_pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it the paper by uploading it to the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread(file_path):\n",
    "    # Upload the file\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        message_file = client.files.create(file=f, purpose=\"assistants\")\n",
    "    \n",
    "    # Create a thread and attach the file to the message\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Here is a research paper. You will be asked to extract multiple things from this paper. Do each task exactly as posed and very carefully. The correct completion of these tasks is VERY IMPORTANT. MAKE NO MISTAKES.\",\n",
    "                \"attachments\": [\n",
    "                    {\"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}]}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return thread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it the task definition and ask it to complete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_message(file_name, thread):\n",
    "    task_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "        You just received a research paper. The file name of the paper is {file_name} Please complete the following tasks:\n",
    "\n",
    "        **Main Objective:**\n",
    "        Your main objective is to extract all relevant test statistics of focal hypothesis tests from the research paper.\n",
    "\n",
    "        *Definition of 'relevant test statistics':*\n",
    "        - A test statistic is relevant if it is used to test a main hypothesis of the research paper.\n",
    "        - Relevant test statistics are typically reported in the results section of the paper.\n",
    "        - Relevant test statistics are typically reported as t, F, z, b, gamma, beta, r, R², etc., potentially including degrees of freedom, and most importantly p-values and sometimes confidence intervals (CIs). Also they may potentially include effect sizes (e.g., Cohen's d).\n",
    "\n",
    "        *Definition of 'focal hypothesis tests':*\n",
    "        - The paper might have multiple main hypotheses and/or multiple studies.\n",
    "        - A hypothesis test is focal if it is a main hypothesis of the paper, typically explicitly or implicitly stated in the introduction or methods section.\n",
    "        - Ensure completeness but remain concise—do not include irrelevant test statistics or fabricate hypotheses.\n",
    "        - A hypothesis can be tested in just one out of all studies, or in multiple studies. If a hypothesis is tested repeatedly, make sure you do not miss this in the extraction.\n",
    "        - Ideally, but by far not always, papers distinguish between pre-registration and exploratory analyses. If so, focus on pre-registered hypotheses only. If no such distinction is made, focus on what you think are the tests of predicted hypotheses.\n",
    "\n",
    "        **Tasks:**\n",
    "        1. Identify the number of studies reported in the paper.\n",
    "        2. Identify the main hypothesis tests reported in the paper.\n",
    "        3. Extract the test statistics for each hypothesis test. Also determine if the hypothesis was confirmed or not based on the p-value and the hypothesized direction.\n",
    "\n",
    "        ** Word of Caution:**\n",
    "        - Be extremely careful with the extraction of test statistics. The correct extraction of test statistics is crucial for the interpretation of the results.\n",
    "        - Sometimes identifying what is important means drawing from a large and extensive context. Make sure to read the paper carefully and fully understand it before starting on the task.\n",
    "\n",
    "        ** Examples of a Test statistic Output:**\n",
    "        - Example 1:\n",
    "        * In the paper:*\n",
    "            \"The results showed a significant effect, F(1,20) = 3.45, p < 0.05, d = .20.\"\n",
    "        * Expected output:*\n",
    "            {{\n",
    "                \"statistic_type\": \"F\",\n",
    "                \"value\": 3.45,\n",
    "                \"degrees_of_freedom\": \"1,20\",\n",
    "                \"p_value_exact\": false,\n",
    "                \"p_value\": 0.05,\n",
    "                \"confidence_interval\": null,\n",
    "                \"effect_measure\": d,\n",
    "                \"effect_size\": \"0.20\"\n",
    "                \"hypothesis_confirmed\": true\n",
    "            }}\n",
    "        - Example 2:\n",
    "            * In the paper:*\n",
    "                \"The correlation was significant, b = 0.35, p = 0.01.\"\n",
    "            * Expected output:*\n",
    "                {{\n",
    "                    \"statistic_type\": \"b\",\n",
    "                    \"value\": 0.35,\n",
    "                    \"degrees_of_freedom\": null,\n",
    "                    \"p_value_exact\": true,\n",
    "                    \"p_value\": 0.01,\n",
    "                    \"confidence_interval\": null,\n",
    "                    \"effect_measure\": null,\n",
    "                    \"effect_size\": null\n",
    "                    \"hypothesis_confirmed\": true\n",
    "                }}\n",
    "\n",
    "        Please provide the extracted information in the specified JSON format.\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Add the task message to the thread\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=task_message[\"role\"],\n",
    "        content=task_message[\"content\"]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the above in a loop for all the papers - done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run method in loop\n",
    "\n",
    "log_file_path = \"log.txt\"\n",
    "\n",
    "t_total = time.time()\n",
    "\n",
    "failed_hyp_path = \"failed_extractions.csv\"\n",
    "\n",
    "json_files_dir = \"./json_files\"\n",
    "\n",
    "# create dir if it does not exist\n",
    "if not os.path.exists(json_files_dir):\n",
    "    os.makedirs(json_files_dir)\n",
    "\n",
    "with open(log_file_path, \"a\") as log_file:\n",
    "    with redirect_stdout(log_file):\n",
    "        print(f\"\\n******************************Starting processing of {len(selected_pdfs)} documents at {t_total}******************************\\n\")\n",
    "        for i, pdf in enumerate(selected_pdfs):\n",
    "            t0 = time.time()\n",
    "            print(f\"\\n******************************Starting processing of document {pdf} at {t0}******************************\\n\")\n",
    "            thread = create_thread(filepath + pdf)\n",
    "            print(f\"Thread created for document {pdf}\")\n",
    "            create_message(pdf, thread)\n",
    "            run = client.beta.threads.runs.create_and_poll(\n",
    "                thread_id=thread.id, assistant_id=assistant.id, model=\"gpt-4o\"\n",
    "            )\n",
    "            print(f\"Run completed for document {pdf}\")\n",
    "            print(run)\n",
    "            messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "            message_content = messages[0].content[0].text\n",
    "            extracted_data = json.loads(message_content.value)\n",
    "            # save to json file\n",
    "            json_file_path = os.path.join(json_files_dir, pdf.replace(\".pdf\", \".json\"))\n",
    "            with open(json_file_path, \"w\") as f:\n",
    "                json.dump(extracted_data, f, indent=2)\n",
    "            t1 = time.time()\n",
    "            print(f\"\\n******************************Finished processing of document {pdf} at {t1}******************************\\n\")\n",
    "            print(f\"Time taken to process document {pdf}: {t1 - t0} seconds\\n\")\n",
    "        t_final = time.time()\n",
    "        print(f\"\\n******************************Finished processing of {len(selected_pdfs)} documents at {t_final}******************************\\n\")\n",
    "        print(f\"Total time taken to process {len(selected_pdfs)} documents: {t_final - t_total} seconds\\n\")\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh yes, and convert to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder containing the JSON files and the output CSV file path\n",
    "input_folder = \"./json_files_4o\"\n",
    "output_csv = '/combined_data.csv'\n",
    "\n",
    "rows = []\n",
    "for filepath in glob(os.path.join(input_folder, '*.json')):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    paper_title = data.get('paper_title', '')\n",
    "    file_name   = data.get('file_name', '')\n",
    "    \n",
    "    for study in data.get('studies', []):\n",
    "        study_title = study.get('study_title', '')\n",
    "        for hypothesis in study.get('hypotheses', []):\n",
    "            hypothesis_text = hypothesis.get('hypothesis_text', '')\n",
    "            for stat in hypothesis.get('test_statistics', []):\n",
    "                row = {\n",
    "                    'paper_title': paper_title,\n",
    "                    'file_name': file_name,\n",
    "                    'study_title': study_title,\n",
    "                    'hypothesis_text': hypothesis_text,\n",
    "                    'statistic_type': stat.get('statistic_type', ''),\n",
    "                    'value': stat.get('value', ''),\n",
    "                    'degrees_of_freedom': stat.get('degrees_of_freedom', ''),\n",
    "                    'p_value_exact': stat.get('p_value_exact', ''),\n",
    "                    'p_value': stat.get('p_value', ''),\n",
    "                    'confidence_interval': stat.get('confidence_interval', ''),\n",
    "                    'effect_measure': stat.get('effect_measure', ''),\n",
    "                    'effect_size': stat.get('effect_size', ''),\n",
    "                    'hypothesis_confirmed': stat.get('hypothesis_confirmed', '')\n",
    "                }\n",
    "                rows.append(row)\n",
    "\n",
    "fieldnames = [\n",
    "    'paper_title', 'file_name', 'study_title', 'hypothesis_text',\n",
    "    'statistic_type', 'value', 'degrees_of_freedom', 'p_value_exact',\n",
    "    'p_value', 'confidence_interval', 'effect_measure', 'effect_size',\n",
    "    'hypothesis_confirmed'\n",
    "]\n",
    "\n",
    "with open(input_folder+output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
